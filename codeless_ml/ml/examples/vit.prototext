user_defined_python_module: [
  "codeless_ml.ml.transformer.schedule",
  "codeless_ml.ml.registry.vit"
]
train_dataset {
  tfds {
      name: "imagenette/160px"
      split: "train"
      data_dir: "codeless_ml/ml/artifacts"
  }
  batch_size: 128
  shuffle_buffer_size: 1024
  pre_batch_map_callable {
    closure {
      function_name: "codeless_ml.ml.registry.create_input_fn"
      argument { key: "new_height"
       value { int32_value: 160 }
      }
      argument {
        key: "new_width"
        value { int32_value: 160 }
      }
      argument {
        key: "num_patches"
        value { int32_value: 10 }
      }
    }
  }
}
validation_dataset {
  tfds {
      name: "imagenette/160px"
      split: "validation"
      data_dir: "codeless_ml/ml/artifacts"
  }
  batch_size: 128
  shuffle_buffer_size: 1024
  pre_batch_map_callable {
    closure {
      function_name: "codeless_ml.ml.registry.create_input_fn"
      argument {
       key: "new_height"
       value { int32_value: 160 }
      }
      argument {
        key: "new_width"
        value { int32_value: 160 }
      }
      argument {
        key: "num_patches"
        value { int32_value: 10 }
      }
    }
  }
}

fit_config {
  epochs: 50
}
save_model_config {
  output_directory: "/tmp/vit3"  
}
checkpoint_config {
  filepath: "/tmp/vit3/cp-{epoch:04d}.ckpt"
}

tensor_board_config {
  log_dir: "/tmp/vit3/tensorboard"
  write_graph: true
  samples: 20
}

model_config {
  name: "vit"
  description: "visual transformer"
  adam_optimizer {
    lr {
      # fixed_rate: 0.01
      custom_schedule {
        closure {
          function_name: "/optimizer/transformer/custom_schedule"
          argument {
            key: "d_model"
            value { int32_value: 768 }
          }
          argument {
            key: "warmup_steps"
            value { int32_value: 4000 }
          }
        }
      }
    }
    beta_1: 0.9
    beta_2: 0.98
    epsilon: 1e-9
  }
  loss_config {
    loss_spec { standard_loss: LOSS_TYPE_SPARSE_CATEGORICAL_CROSSENTROPY }
  }
  metric_config {
    metric_spec { standard_metric:  METRIC_TYPE_SPARSE_CATEGORICAL_ACCURACY }
  }
  layer {
    name: "pos_token"
    input {
      # 10 * 10 patches + [CLS] token
      shape: [101]
      dtype: "int32"
      sparse: false
    }
  }
  layer {
    name: "cls_token"
    input {
      shape: [1]
      dtype: "int32"
      sparse: false
    }
  }
  layer {
    name: "patch"
    input {
      # the last dimension: 16 x 16 x 3
      shape: [-1, 768]
      dtype: "float"
      sparse: false
    }
  }
  # project the patches into embeddings.
  layer {
    name: "patch_emb"
    dense {
      units: 768
      activation: ACTIVATION_TYPE_LINEAR
    }
    dependency { name: "patch" }
  }
  layer {
    name: "cls_emb"
    embedding {
      # only one token needed.
      input_dim: 1
      output_dim: 768
    }
    dependency { name: "cls_token" }
  }
  layer {
    name: "concat_emb"
    custom_callable {
      function_name: "codeless_ml.ml.registry.concat_embeddings"
    }
    dependency { name: "cls_emb" }
    dependency { name: "patch_emb" }
  }
  layer {
    name: "pos_emb"
    embedding {
      # vocab size = 1 (cls) + 10 * 10 patches  
      input_dim: 101
      output_dim: 768
    }
    dependency { name: "pos_token" }
  }
  layer {
    name: "add_emb"
    add {}
    dependency { name: "pos_emb" }
    dependency { name: "concat_emb" }
  }
  layer {
    name: "encoder"
    transformer_encoder {
      num_layers: 8
      d_model: 768
      num_heads: 8
      dff: 2048
      dropout_rate: 0.1
    }
    dependency { name: "add_emb" }
  }
  layer {
    name: "extract_cls"
    custom_callable {
      function_name: "codeless_ml.ml.registry.extract_cls_embedding"
    }
    dependency {name: "encoder"}
  }
  layer {
    name: "mlp"
    dense {
      units: 2048
      activation: ACTIVATION_TYPE_TANH
    }
    dependency { name: "extract_cls" }
  }
  layer {
    name: "target"
    dense {
      units: 10
      activation: ACTIVATION_TYPE_SOFTMAX
    }
    is_output: true
    dependency { name: "mlp" }
  }
}
